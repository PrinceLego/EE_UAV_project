\documentclass[12pt]{article}       % 設定文件類型為 article，字體大小為 12pt
\usepackage[T1]{fontenc}            % 設定 T1 字型編碼，確保特殊字元的正確顯示
\usepackage{lmodern}                % 強制使用 Latin Modern 字型，提高可讀性和相容性
\usepackage{fontspec}               % 允許使用 OpenType 和 TrueType 字型
\usepackage{graphicx}               % 支援插入圖片
\usepackage{amsmath}                % 提供數學環境和公式支持
\usepackage{csquotes}               % 提供引用格式支援
\usepackage{comment}                % 提供多行註解
\usepackage{ragged2e}
\usepackage{amsmath}
\usepackage{float}
\usepackage{booktabs} % 專業表格格式
\usepackage{siunitx}  % 數值對齊

%biber NSTC_project

%=================================================={{{參考文獻設定}}}==================================================

\usepackage[style=ieee, maxnames=99]{biblatex}          % 設定參考文獻格式為 IEEE，最多顯示 99 個作者
\addbibresource{NSTC_project.bib}                       % 添加參考文獻檔案 references.bib
\renewcommand{\bibfont}{\fontspec{Times New Roman}}     % 設定參考文獻字體為 Times New Roman
\renewcommand{\UrlFont}{\fontspec{Times New Roman}}     % 設定 URL 連結字體為 Times New Roman
\DeclareFieldFormat{url}{\url{#1}}                      % 格式化 URL
\bibliography{your_bib_file}                            % 引用你的 .bib 文件

%=================================================={{{目錄設定}}}==================================================

\usepackage{tocloft} % 自訂目錄格式

% 設定目錄的點線填充樣式
\renewcommand{\cftsecleader}{\cftdotfill{\cftdotsep}}           % 章節（section）
\renewcommand{\cftsubsecleader}{\cftdotfill{\cftdotsep}}        % 小節（subsection）
\renewcommand{\cftsubsubsecleader}{\cftdotfill{\cftdotsep}}     % 子小節（subsubsection）

% 設定圖目錄與表目錄的點線
\renewcommand{\cftdotsep}{1}  % 設定點的間距，使其在所有目錄（含圖、表）中都有效

% 設定目錄標題格式，使目錄、圖目錄、表目錄標題一致
\renewcommand{\contentsname}{\centering \LARGE \textbf{目錄}}    % 目錄標題置中，加粗
\renewcommand{\listfigurename}{\centering \LARGE \textbf{圖目錄}} % 圖目錄標題置中，加粗
\renewcommand{\listtablename}{\centering \LARGE \textbf{表目錄}} % 表目錄標題置中，加粗


%=================================================={{{字體設定}}}==================================================

% 設定英文字體
\newfontface\englishfont{Times New Roman}               % 自訂英文字體命令 \englishfont，使用 Times New Roman

\setmainfont[
    ItalicFont={Times New Roman Italic},                % 設定斜體
    BoldFont={Times New Roman Bold},                    % 設定粗體
    BoldItalicFont={Times New Roman Bold Italic}        % 設定粗斜體
]{Times New Roman}                                      % 設定主要英文字體為 Times New Roman

% 設定中文字體

\usepackage{xeCJK}                                      % 使用 xeCJK 宏包以支援中文
\renewcommand{\figurename}{圖}                           % 設定圖表名稱
\renewcommand{\tablename}{表}                            % 修改表格標題為「表」
\setCJKmainfont[BoldFont={標楷體-繁}, ItalicFont={標楷體-繁}] {標楷體-繁}

%=================================================={{{版面設定}}}==================================================

% 設定頁面邊界，適用 A4 紙張
\usepackage[top=2cm, bottom=2cm, left=2cm, right=2cm, a4paper]{geometry}

% 設定行距與段落格式
\usepackage{setspace}
\onehalfspacing % 設定 1.5 倍行距
\setlength{\parskip}{6pt} % 設定段落間距 6pt
\setlength{\parindent}{2em} % 設定段落首行縮排 2 個字元

%=============================================================================================================================
%=============================================================================================================================
%=============================================================================================================================

\begin{document}

\pagenumbering{roman}  
\setcounter{page}{1}  % 從 I 開始

%=================================================={{{中文摘要}}}==================================================

\section*{\centering 摘要}  % 只讓標題置中
\addcontentsline{toc}{section}{摘要}  % 手動加入摘要到目錄

%==============================摘要內容==============================

\hspace{2em}
本研究計畫旨在開發一套智慧交通巡檢系統，利用四軸飛行載具（Unmanned Aerial Vehicle, UAV）進行違規停車車輛的偵測。
不同於以往先判斷紅線位置再確認車輛是否違規的方法，本研究透過四軸飛行器的GPS定位資訊來判斷車輛是否違規，避免車輛停在紅線上或完全遮掩紅線的情況。
由於系統僅檢視違規區域，此方法還能加快巡邏速度，提升巡邏效率。

本系計畫統採用YOLOv7物件偵測模型進行即時車輛辨識，結合飛行器的姿態與相機拍攝角度，
利用逆透視變換(Inverse Perspective Mapping，IPM)定位，將偵測結果轉換為地面上的絕對位置，這樣能夠快速確定違規停車車輛的位置。
透過事先建立的資料庫，無人機將比對飛越指定區域所拍攝的影像，並即時偵測違規車輛，記錄其位置。
該系統的優勢在於高效的監控能力，能夠大幅減少設備投資成本，並提升違規車輛檢測的靈活性和即時性。

\vspace{1.5em}
\noindent 關鍵字：即時物件偵測、四旋翼無人機、空間對位
%==============================摘要內容==============================
\newpage  % 插入換頁命令，將目錄和後續內容分開

%=================================================={{{英文摘要}}}==================================================
\section*{\centering Abstract}  % 只讓標題置中
\addcontentsline{toc}{section}{Abstract}  % 手動加入摘要到目錄
%==============================摘要內容==============================
\hspace{2em}This research aims to develop an intelligent traffic inspection system utilizing unmanned aerial vehicles (UAVs) to detect illegally parked vehicles.
Unlike conventional methods that first identify the location of red lines and then verify whether vehicles are violating parking regulations, this system determines whether a vehicle is in violation by using the UAV's GPS positioning information, preventing vehicles from parking on or completely covering red lines.
Since the system only inspects the violation areas, this approach helps speed up patrol operations and enhance overall patrol efficiency.

This research adopts the YOLOv7 object detection model for real-time vehicle identification, combined with the UAV's attitude and camera angle.
By using Inverse Perspective Mapping, the system locates and converts the detection results into absolute ground positions, allowing for quick identification of illegally parked vehicles.
Through a pre-established database, the UAV compares the images captured while flying over designated areas and immediately detects violation vehicles, recording their locations. The advantage of this system lies in its efficient monitoring capability, significantly reducing equipment investment costs and improving the flexibility and immediacy of illegal parking detection.

\vspace{1.5em}
\noindent Keyword: Real-time Object Detection, Quadcopter, Georeferencing
%==============================摘要內容==============================
\newpage  % 插入換頁命令，將目錄和後續內容分開

%=================================================={{{目錄}}}==================================================

\begin{center}
    \tableofcontents    % 生成目錄
    \newpage  % 插入換頁命令，將目錄和後續內容分開
    \addtocontents{toc}{\protect\setcounter{tocdepth}{0}} % 暫時關閉目錄深度，讓圖目錄不顯示在目錄中
    \listoffigures      % 生成圖目錄
    \addtocontents{toc}{\protect\setcounter{tocdepth}{2}} % 恢復目錄深度（如果你的章節結構需要更深層級，請調整數值）
    \newpage  % 插入換頁命令，將目錄和後續內容分開
    \listoftables       % 生成表目錄
\end{center}
    
    \newpage  % 插入換頁命令，將目錄和後續內容分開
%=================================================={{{內容開始}}}==================================================

\pagenumbering{arabic}  % 開始使用阿拉伯數字頁碼
\setcounter{page}{1}  % 設定頁碼從 1 開始

%\englishfont{this is an example of mixed English and Chinese.}

\section{\centering 緒論}

\subsection{研究背景} 
%==============================內文==============================
\hspace{2em}
無人機（Unmanned Aerial Vehicle, UAV）技術近年來快速發展，整合各種附加設備並隨著飛行控制與自動化技術的成熟，在軍事、執法及科技應用領域取得顯著成效。
四軸旋翼無人機因其安全性高、成本低的優勢，已廣泛應用於各種場景，其中攝影與錄影功能尤為重要。
無人機擁有比傳統攝影設備更廣的視角，且受環境限制較小，使其在大範圍場景捕捉方面表現優異，優於傳統監控方式。

在交通監控領域，無人機的靈活性和效率遠勝於傳統固定式監控設備，如固定式照相桿雖能執行監控任務，但監測範圍有限且設備成本較高。
隨著無人機技術的進步，其在交通巡檢方面展現出極大的應用潛力，特別是在違規停車偵測方面，無人機能夠提供更靈活且高效的解決方案。
目前，中國部分城市已開始運用無人機進行科技執法\cite{chinatimes2019}，台北市與台中市警察局亦已成立無人機機隊\cite{cna_2022}\cite{tai_2021}，用於交通監測與執法，並協助執法人員即時掌握交通狀況，提升執法效率。

\begin{figure}[H]
    \centering
    \renewcommand{\figurename}{圖} %顯示圖1，不是figureat1
    \includegraphics[width=0.7\textwidth]{research_problem1.jpg}     %圖片檔案名稱
    \caption{無人機偵測違停車輛示意圖}    %圖片檔案名稱
    \label{fig:research_problem1}    %為圖片添加標籤
    %圖\ref{fig:無人機偵測違停車輛示意圖}
\end{figure}
%==============================內文==============================

\subsection{研究動機} 
%==============================內文==============================
\hspace{2em}目前的研究和應用大多針對車輛橫跨紅線進行判斷，但對於完全蓋住紅線或停在紅線與白線交界處的情況，現有方法無法準確判斷車輛是否違停。
因此，本研究計畫的動機在於利用無人機的GPS位置資訊來判斷車輛的違規情形，避免車輛完全遮掩紅線或停在紅線邊界處的情況。
如圖\ref{fig:research_problem2} 所示。
並通過建立資料庫並使用無人機拍攝影像，比對車輛所處位置與違規區域，能夠快速偵測違規車輛並進行即時回報，進一步提升交通執法的效率與靈活性。

\begin{figure}[H]
    \centering
    \renewcommand{\figurename}{圖} %顯示圖1，不是figureat1
    \includegraphics[width=0.7\textwidth]{research_problem2.jpg}     %圖片檔案名稱
    \caption{本計畫研究問題之示意圖}    %圖片檔案名稱
    \label{fig:research_problem2}    %為圖片添加標籤
    %圖\ref{fig:example1}
\end{figure}
%==============================內文==============================

\subsection{研究問題} 
%==============================內文==============================
\hspace{2em}利用無人機拍攝出的影像辨識出沿路車輛，利用無人機本身 GPS 位置，換算出影像中車輛之位置，比對車輛所在位置是否可以停車，
以判斷車輛否違規，若有違規情形，回傳車輛位置並將其建立成資料庫，以便於人員複查或是違規檢舉。研究問題可以分為三大項，違規車輛偵測、影像處理、空間對位。
%==============================內文==============================

\subsubsection{違規車輛偵測}
%==============================內文==============================
\hspace{2em}為了精確偵測違規停放的車輛，本系統採用先進的影像辨識技術，利用 YOLOv7 進行即時車輛偵測，確保能快速且準確地識別影像中的車輛。
透過無人機高空巡檢，可大範圍覆蓋監控區域。此外，系統將結合 GPS 位置資訊，以判斷車輛是否位於可能的違規區域，
如紅線停車區、消防通道或人行道上，進一步提高偵測的可靠性與準確性。
%==============================內文==============================

\subsubsection{影像處理}
%==============================內文==============================
\hspace{2em}本計畫將利用鏡頭往斜下的角度拍攝而非垂直向下。以斜下角度拍攝的特點是相較於垂直向下拍攝可以擁有較大的視野範圍。
而採用無人機的 GPS位置資訊判斷，無人機拍攝圖片中每個像素與實際地面之關係格外重要，除了無人機上相機的傾角，
還需整合無人機在飛行時的對地高度、翻滾角 (Roll)、俯仰角(Pitch)、偏航角(Yaw)等慣性測量單元(Inertial measurement unit, IMU)，
並依據該照片拍攝時之IMU資訊做正射投影，運算每個像素與無人機之間的相對位置，並依照無人機的GPS位置準確定位違規車輛之位置。
%==============================內文==============================

\subsubsection{空間對位}
%==============================內文==============================
\hspace{2em}為確保偵測結果的精準性，系統將進行空間對位處理，以克服飛行器姿態變化、鏡頭視角與透視變形等因素所造成的誤差。
透過飛行器的 IMU（慣性測量單元）數據與 GPS 定位資訊，獲取無人機的姿態與拍攝角度，並利用透視變換技術將影像坐標轉換為地面絕對位置。
最後，系統將偵測出的車輛位置與電子地圖上的違規區域進行重合度分析，精確確認車輛是否確實違規停放，並輸出違規證據以供後續處理。
%==============================內文==============================

\section{\centering 文獻探討與回顧}

\subsection{應用YOLOv7於車輛物件偵測}
%==============================內文==============================
\hspace{2em}違規停車偵測的部分預計使用物件偵測深度神經網路，找出車輛位置，以判斷車輛是否違規，利用物件偵測深度神經網路，不管是在標註樣本或是進行訓練上都可以節省許多的時間，並且擁有較高的準確度。
本計畫採用知名的物件偵測深度神經網YOLO，其全名為You Only Look Once，首次出現於 2015 年，由 Joseph Redmon 和 Ali Farhadi 等人提出\cite{ren_2015}。
YOLO能夠在實時情況下執行物體檢測，這意味著它可以快速地識別圖像中的物體，並且適用於需要即時反饋的應用場景，相較於其他物體檢測算法，YOLO算法在準確性上表現出色，能夠有效地檢測各種大小和形狀的物體，相對於其他複雜的物體檢測算法而言，實現起來相對簡單，這使得它受到廣泛的歡迎並且易於應用於各種領域，有實時檢測、高準確性、簡單易用、可擴展性等優點。

\begin{figure}[H]
    \centering
    \renewcommand{\figurename}{圖} %顯示圖1，不是figureat1
    \includegraphics[width=0.7\textwidth]{yolov7_1.jpg}     %圖片檔案名稱
    \caption{YOLO各版本演進圖\cite{tencent2023}}    %圖片檔案名稱
    \label{fig:yolov7_1}    %為圖片添加標籤
    %如圖\ref{fig:yolov7_1}所示
\end{figure}

本研究選用YOLOv7\cite{wang2023yolov7}作為物件偵測算法，其為YOLO系列中的高效版本，具有優異的準確性與速度(如圖\ref{fig:yolov7_2} 所示)。YOLOv7屬於one stage物件偵測方法，能夠在單次運行中同時完成位置偵測與物件分類，相較於two stage方法，其運算速度更快，且準確度仍維持在可接受範圍內。
YOLOv7在架構設計上延續了YOLOv3的基本結構，包括主幹網路(Backbone)、連接層(Neck)與檢測頭(Head)，並透過引入新技術進一步提升效能(如圖\ref{fig:yolov7_3} 所示)。
Backbone負責特徵提取，輸入圖像經過多層卷積運算，從B1至B5逐步提取更加豐富的特徵資訊，特徵圖尺寸逐漸縮小，但通道數量增加；Neck透過上採樣(upsampling)擴增特徵圖，並透過橫向連結融合不同層級的特徵，使模型能夠有效學習多尺度資訊；
Head則負責最終檢測結果的輸出，透過下採樣(subsampling)還原金字塔結構，最終產生多種解析度的特徵圖(P3、H4、H5)以適應不同大小的物件偵測需求。此外，YOLOv7透過模型重參數化(Re-parameterized model)改進模型結構以提高推理速度，並提出Extend-ELAN(E-ELAN)，在不破壞梯度傳播的情況下增強網路學習能力。
透過這些技術，YOLOv7在物件偵測任務中展現了更優異的效能，能夠在高準確度與低延遲之間取得良好平衡，適用於多種應用場景。

\begin{figure}[H]
    \centering
    \renewcommand{\figurename}{圖}                              %顯示圖1，不是figureat1
    \includegraphics[width=0.7\textwidth]{yolov7_2.jpg}         %圖片檔案名稱
    \caption{YOLOv7與其它模型比較\cite{wang2023yolov7}}           %圖片檔案名稱
    \label{fig:yolov7_2}                                        %為圖片添加標籤
    %(如圖\ref{fig:yolov7_2} 所示)
\end{figure}

\begin{figure}[H]
    \centering
    \renewcommand{\figurename}{圖} %顯示圖1，不是figureat1
    \includegraphics[width=0.7\textwidth]{yolov7_3.jpg}     %圖片檔案名稱
    \caption{YOLOv7架構圖\cite{hackmd}}    %圖片檔案名稱
    \label{fig:yolov7_3}    %為圖片添加標籤
    %(如圖\ref{fig:yolov7_3} 所示)
\end{figure}
%==============================內文==============================

\subsection{應用VBS-RTK之GPS定位}
%==============================內文==============================
\hspace{2em}在定位方面採用即時動態定位技術(Virtual Base Station Real-Time Kinematic, VBS-RTK)以獲得無人機精確位置，VBS-RTK是e-GNSS 即時動態定位系統之核心定位技術。
其係採用多個衛星定位基準站所組成的 GNSS 網絡來評估基準站涵蓋地區之定位誤差，再配合最鄰近的實體基準站觀測資料，產製一個虛擬的基準站做為RTK主站，所以移動站並不是接收某個實體基準站之實際觀測資料，而是經過誤差修正後的虛擬觀測數據。

\begin{figure}[H]
    \centering
    \renewcommand{\figurename}{圖}                              %顯示圖1，不是figureat1
    \includegraphics[width=0.7\textwidth]{vbsrtk.jpg}         %圖片檔案名稱
    \caption{VBS-RTK運作流程圖\cite{egnss_2020}}           %圖片檔案名稱
    \label{fig:vbsrtk}                                        %為圖片添加標籤
    %(如圖\ref{fig:yolov7_2} 所示)
\end{figure}
%==============================內文==============================

\subsection{影像處理與空間對位}
%==============================內文==============================
\hspace{2em}本計畫將利用鏡頭往斜下的角度拍攝而非垂直向下。以斜下角度拍攝的特點是相較於垂直向下拍攝可以擁有較大的視野範圍。
這部分需應用航空攝影測量原理\cite{zhao2013}的中共線方程式(Collinearity equation)求得地面點在像片上對應之坐標，共線方程式係基於透視中心投影之原則下根據物點、像點、以及攝影時的參數所建立，求得每一地面點在相片上對應之坐標。

\begin{figure}[H]
    \centering
    \renewcommand{\figurename}{圖}                              %顯示圖1，不是figureat1
    \includegraphics[width=0.7\textwidth]{ce.jpg}         %圖片檔案名稱
    \caption{共線式幾何示意圖\cite{tsao2018}}           %圖片檔案名稱
    \label{fig:ce}                                        %為圖片添加標籤
    %(如圖\ref{fig:yolov7_2} 所示)
\end{figure}
%==============================內文==============================

\section{\centering 研究方法及流程}
%==============================內文==============================
\hspace{2em}本計畫要設計的電腦應用程式，能夠標示出地圖中不可停車的區域，而無人機則透過事先建立的資料庫，
比對飛越指定區域所拍攝的影像，快速辨識違規車輛並記錄其車牌號碼，運作流程如\ref{fig:flow_chart}所示。
\begin{figure}[H]
    \centering
    \includegraphics[width=0.7\textwidth]{flow_chart.jpg}     %圖片檔案名稱
    \caption{研究流程圖}    %圖片檔案名稱
    \label{fig:flow_chart}    %為圖片添加標籤
    %如\ref{fig:flow_chart}所示
\end{figure}
本研究中所使用的無人機，為委託臺灣希望創新股份有限公司(Taiwan Hope Innovation Corporation)所特別製作的無人機，實驗中使用的無人機為含有 Pixhawk4 Orange飛控板、樹梅派、GPS、HUAWEI 4G USB 網卡和 Logitech C922 Pro Stream單目攝像頭(具體規格詳見表\ref{tab:C922 Pro})的四軸飛行器。
錄製到的影像透過無人機上的樹梅派傳送到RTMP server \cite{chen2011}\cite{mark2018}。在由其他電腦從RTMP server取得影像並做辨識。為了使無人機飛行更順利，無人機上含有高性能的飛控板、精確的 GPS 定位系統，在兩者相互搭配下，使無人機有更穩定的飛行。

\begin{figure}[H]
    \centering
    \includegraphics[width=0.7\textwidth]{UAVphoto.jpg}     %圖片檔案名稱
    \caption{本研究所使用之無人機}    %圖片檔案名稱
    \label{fig:UAVphoto}    %為圖片添加標籤
    %如\ref{fig:example1}所示
\end{figure}

\begin{figure}[H]
    \centering
    \includegraphics[width=0.7\textwidth]{c922.jpg}     %圖片檔案名稱
    \caption{本研究使用之單目攝像頭\cite{logitech}}    %圖片檔案名稱
    \label{fig:c922}    %為圖片添加標籤
    %如\ref{fig:c922}所示
\end{figure}

\begin{table}[H]
    \centering
    \caption{C922 Pro Stream 規格}
    \vspace{6pt} % 增加空格
    \label{tab:C922 Pro}
    \begin{tabular}{ll}
        \toprule
        \textbf{項目} & \textbf{規格} \\
        \midrule
        解析度  & 1280$\times$720 (HD) \\
        幀率  & 30fps \\
        水平視角 & 70.42$^\circ$ \\
        垂直視角  & 43.3$^\circ$ \\
        \bottomrule
    \end{tabular}
\end{table}

無人機控制方面透過4G網卡及VPN以遠端控制樹莓派，並且在樹莓派中我們透過MAVProxy(MAVLink Proxy)\cite{mavproxy_2023}指令將飛控板透過UDP方式連線至電腦端的Mission Planner\cite{pixhawk_2023}，
Mission Planner 提供了一個實時的飛行監控界面(如圖\ref{fig:missionplanner}所示)，可編輯飛行計劃，並記錄飛行數據。
\begin{figure}[H]
    \centering
    \includegraphics[width=0.7\textwidth]{missionplanner.jpg}     %圖片檔案名稱
    \caption{Mission Planner實際畫面\cite{pixhawk_2023}}    %圖片檔案名稱
    \label{fig:missionplanner}    %為圖片添加標籤
    %(如圖\ref{fig:missionplanner}所示)
\end{figure}
本實驗透過 4G 網路 連接無人機進行控制，並在電腦端使用 ROS 進行影像擷取與處理。
此外，在影像處理的同時，還需透過 Mission Planner 即時控制無人機並藉由 MAVLink 協議獲取相關資訊。
因此，筆記型電腦必須具備足夠的性能，以確保系統的穩定運行與即時回應。

本計畫中，主要使用 MSI GP76 Leopard 筆記型電腦(具體規格詳見表\ref{tab:macbook_m1})。
該機型以高效能為主打，搭載 Intel® Core™ i7-10870H 處理器與 NVIDIA® GeForce® RTX 3060 顯示卡，並採用 MSI 最新技術 Cooler Boost 5。其雙散熱模組設計、強力雙風扇與多組熱管，加上四向散熱氣流設計，能有效排除廢熱，確保處理器與顯示卡在高負載運行時維持最佳性能。

本計畫也輔以 Apple MacBook M1 (具體規格詳見表\ref{tab:macbook_m1})進行部分運算與開發工作。
MacBook M1 採用 Apple M1 晶片，內建 8 核心 CPU 及 7 核心 GPU，並配備 8GB 統一記憶體(Unified Memory)，提供優異的效能與低功耗表現。在本研究中，MacBook M1 主要用於 ROS 1 相關開發、Python 影像處理、無人機數據分析與程式開發。
不過，由於 M1 晶片採用 ARM 架構，與傳統 x86 架構不同，在執行 ROS 及部分開發環境時，需透過 Docker 來確保軟體相容性。

\begin{table}[H]
    \centering
    \caption{MacBook Air M1 與比較機種規格}
    \vspace{6pt} % 增加空格
    \label{tab:macbook_m1}
    \begin{tabular}{lll}
        \toprule
        \textbf{元件} & \textbf{MacBook Air M1} & \textbf{MSI GP76 Leopard} \\
        \midrule
        處理器 (CPU)  & Apple M1 (8 核心) & Intel\textregistered{} Core\texttrademark{} i7-10870H \\
        記憶體 (RAM)  & 8GB Unified Memory & 16GB DDR4 \\
        硬碟 (Storage) & 256GB SSD  & 1TB SSD \\
        顯示卡 (GPU)  & Apple M1 內建 GPU (7 核心) & NVIDIA\textregistered{} GeForce\textregistered{} RTX 3060 \\
        作業系統 (OS)  & macOS Sequoia & Ubuntu 18.04 \\
        電池容量 (Battery) & 49.9Wh & 65Wh \\
        \bottomrule
    \end{tabular}
\end{table}

綜合而言，MSI GP76 Leopard 主要負責高負載的影像處理與無人機控制，而 MacBook M1 則用於負責高負載的影像處理、程式開發與數據分析，兩者搭配可有效提升本實驗的運算效率與工作流程。
%==============================內文==============================

\subsection{違規車輛偵測}
%==============================內文==============================
\hspace{2em}在車輛偵測方面，透過物件辨識技術YOLO(You Only Look Once)，能夠高效、精確地辨識影像中的車輛。
YOLO是一種基於深度學習的物件偵測模型，能夠在單一的前向傳播過程中，同時進行分類與定位，從而達到快速處理的效果。
結合深度學習技術，YOLO能夠對車輛進行實時的辨識與定位，並在影像中標註出車輛的具體位置。
這不僅提高了車輛偵測的準確性，也能在多種複雜環境下有效運行，無論是白天、夜間，還是不同的天氣條件下。
藉由這些辨識出的資訊，系統可以進一步進行車輛是否違規的判斷。
\begin{figure}[H]
    \centering
    \includegraphics[width=0.7\textwidth]{yolov7car.jpg}     %圖片檔案名稱
    \caption{YOLOv8違規車輛偵測示意圖}    %圖片檔案名稱
    \label{fig:yolov7car}    %為圖片添加標籤
    %(如圖\ref{fig:yolov7car}所示)
\end{figure}
%==============================內文==============================

\subsection{影像處理}
%==============================內文==============================
\hspace{2em}無人機的座標系統定義如圖\ref{fig:xyzppr}所示。$y$軸的正方向為北方$x$軸與$y$軸垂直且以東方為正。
航向角$\psi$是以$yz$平面為基準，沿著$z$軸順時針旋轉的角度，範圍從0$^\circ$到360$^\circ$。
俯仰角$\theta$是以$xy$平面為基準，沿著$x$軸逆時針旋轉為正的角度，範圍從90$^\circ$到-90$^\circ$。
滾轉角$\phi$是以$xy$平面為基準，繞著$y$軸順時針旋轉的角度，範圍從-90$^\circ$到90$^\circ$。
無人機上的攝像頭默認朝向座標系的正$y$軸方向，攝像頭傾斜角度為$\theta_{c}$，範圍從0$^\circ$到-90$^\circ$，攝像頭位置與無人機重心距離忽略不計。
\begin{figure}[H]
    \centering
    \includegraphics[width=0.7\textwidth]{xyzppr.jpg}     %圖片檔案名稱
    \caption{無人機座標系統定義}    %圖片檔案名稱
    \label{fig:xyzppr}    %為圖片添加標籤
    %(如圖\ref{fig:xyzppr}所示)
\end{figure}

本計畫將利用鏡頭往斜下的角度拍攝而非垂直向下，首先測試單純考慮無人機相機傾斜之投影，根據航空攝影測量原理\cite{zhao2013}，可推導出以下公式。
$P_{r}(u_{r},v_{r})$照片上的一個點，$P_{v}(u_{v},v_{v})$為其在正射投影上的對應點(如圖\ref{fig:ipm} 所示)。以$A$表示為相片中心在鳥瞰圖上的對應點，並定為鳥瞰圖座標系的原點。$f$為焦距，原照片與正射投影的對應關係可由以下算式求得：
\begin{align}
    u_{v}=f\times\sec(\theta_{c}-\arctan\frac{v_{r}}{f})\times\frac{u_{r}}{\sqrt{v^2_{r}+f^2}} 
    \label{eq:uv}
    \\
    \label{eq:vv}        
    v_{v}=f\times(\tan\theta_{c}-\tan(\theta_{c}-\arctan\frac{v_{r}}{f}))              
\end{align}
\begin{figure}[H]
    \centering
    \renewcommand{\figurename}{圖}                              %顯示圖1，不是figureat1
    \includegraphics[width=0.7\textwidth]{ipm.jpg}         %圖片檔案名稱
    \caption{非垂直投影示意圖\cite{tsao2018}}           %圖片檔案名稱
    \label{fig:ipm}                                        %為圖片添加標籤
    %(如圖\ref{fig:ipm} 所示)
\end{figure}

本計畫將利用鏡頭往斜下的角度拍攝而非垂直向下，且飛行時會產生翻滾角 (Roll)、俯仰角(Pitch)，以上因素皆會影響成像。
因此本研究採用逆透視變換(Inverse Perspective Mapping，IPM)\cite{lin_2001}\cite{bertozz1998stereo}\cite{mallot1991inverse}技術處理無人機拍攝的影像，以將像素座標轉換為地面座標，最後轉換成GPS座標。

首先將影像像素座標系$(u,v)$轉換為圖像座標系$(x,y)$。
加入相機的水平視角$HFOV$與相機的垂直視角$VFOV$、相機俯仰角$\theta_{c}$，無人機姿態則藉由 mavlink 從 mission planner 獲取俯仰角$\theta_{q}$、滾轉角$\phi_{q}$、航向角$\psi_{q}$，將圖像座標轉換為相機座標$(x_{c},y_{c},z_{c})$。
接著將相機座標系轉換為無人機標系$(x_w,y_w,z_w)$，以取得拍攝影像中內容物與無人機之相對位置。流程圖如下：
\begin{figure}[H]
    \centering
    \includegraphics[width=0.7\textwidth]{pt.jpg}     %圖片檔案名稱
    \caption{座標轉換流程圖}    %圖片檔案名稱
    \label{fig:pt}    %為圖片添加標籤
    %(如圖\ref{fig:yolov7car}所示)
\end{figure}

將像素座標轉換為無人機相對於地平面的世界座標時，過程涉及相機的內參矩陣$K$、旋轉矩陣$R$以及無人機對地高度(相機高度)$h$。要算相機的內參矩陣首先需得出影像的水平焦距$f_{x}$、影像的垂直焦距$f_{y}$和影像的中心座標$(c_x,c_y)$。

影像的水平焦距$f_{x}$公式如式(\ref{eq:fx})，W為影像的寬度，HFOV為相機的水平視角。
影像的垂直焦距$f_{y}$公式如式(\ref{eq:fy})，H為影像的寬度，VFOV為相機的垂直視角。
\begin{align}
    f_{x}=\frac{W}{2\cdot\tan\left(\frac{HFOV}{2}\right)}
    \label{eq:fx}
    \\
    f_{y}=\frac{H}{2\cdot\tan\left(\frac{VFOV}{2}\right)}
    \label{eq:fy}
\end{align}

影像的中心座標$(c_x,c_y)$公式如式(\ref{eq:cx})、式(\ref{eq:cy})：
\begin{align}
    c_{x}=\frac{W}{2}
    \label{eq:cx}
    \\
    c_{y}=\frac{H}{2}
    \label{eq:cy}
\end{align}

式(\ref{eq:k})為相機內參矩陣K。
\begin{align}
    K &=
    \begin{bmatrix}
        f_{x}       & 0             & c_{x}     \\
        0           & f_{y}         & c_{y}     \\
        0           & 0             & 1
    \end{bmatrix} 
    \label{eq:k}
\end{align}

旋轉矩陣R用來表示相機相對於世界座標系的旋轉。無人機共有三個旋轉角度：俯仰角$\theta_{q}$、滾轉角$\phi_{q}$、航向角$\psi_{q}$。
航向角旋轉矩陣$R_{yaw}$、俯仰角旋轉矩陣$R_{pitch}$、滾轉角旋轉矩陣$R_{roll}$的公式分別是式(\ref{eq:ryaw})、式(\ref{eq:rpitch})、式(\ref{eq:rroll})。
\begin{align}
    R_{yaw} &=
    \begin{bmatrix}
        \cos\psi_{q}   & -\sin\psi_{q}  & 0 \\
        \sin\psi_{q}   & \cos\psi_{q}   & 0 \\
        0              & 0              & 1
    \end{bmatrix} 
    \label{eq:ryaw}
    \\
    R_{pitch} &=
    \begin{bmatrix}
        1   & 0  & 0 \\
        0   & \cos(\theta_{q}+\theta_{c})   & -\sin(\theta_{q}+\theta_{c}) \\
        0   & \sin(\theta_{q}+\theta_{c})   & \cos(\theta_{q}+\theta_{c})
    \end{bmatrix} 
    \label{eq:rpitch}
    \\
    R_{roll} &=
    \begin{bmatrix}
        \cos\phi_{q}    & 0     & \sin\phi_{q}  \\
        0               & 1     & 0             \\
        -\sin\phi_{q}   & 0     & \cos\phi_{q}
    \end{bmatrix} 
    \label{eq:rroll}
\end{align}

其組合的旋轉矩陣$R$如式(\ref{eq:R1})、式(\ref{eq:R2})：
\begin{align}
    R=R_{yaw}\cdot R_{pitch} \cdot R_{roll}
    \label{eq:R1}
\end{align}
\begin{align}
    R=
    \begin{bmatrix}
        \cos\psi_{q}   & -\sin\psi_{q}  & 0 \\
        \sin\psi_{q}   & \cos\psi_{q}   & 0 \\
        0              & 0              & 1
    \end{bmatrix} 
    \cdot
    \begin{bmatrix}
        1   & 0  & 0 \\
        0   & \cos(\theta_{q}+\theta_{c})   & -\sin(\theta_{q}+\theta_{c}) \\
        0   & \sin(\theta_{q}+\theta_{c})   & \cos(\theta_{q}+\theta_{c})
    \end{bmatrix} 
    \cdot
    \begin{bmatrix}
        \cos\phi_{q}    & 0     & \sin\phi_{q}  \\
        0               & 1     & 0             \\
        -\sin\phi_{q}   & 0     & \cos\phi_{q}
    \end{bmatrix} 
    \label{eq:R2}
\end{align}

將像素座標系$(x,y)$轉換為圖像座標系的公式如式(\ref{eq:xy1})：
\begin{align}
    \begin{bmatrix}
        x       \\
        y    \\
        1        
    \end{bmatrix} 
     &=K^{-1}\cdot
     \begin{bmatrix}
        u       \\
        v       \\
        1        
    \end{bmatrix} 
    \label{eq:xy1}
\end{align}

將圖像座標系轉換為相機座標系的公式如式(\ref{eq:xcyczc})：
\begin{align}
    \begin{bmatrix}
        x_{c}   \\
        y_{c}   \\
        z_{c}        
    \end{bmatrix} 
     &=R\cdot
     \begin{bmatrix}
        x       \\
        y       \\
        1        
    \end{bmatrix} 
    \label{eq:xcyczc}
\end{align}

將相機座標系轉換為世界座標系$(x_{w},y_{w},z_{w})$的公式見式式(\ref{eq:xw})、式式(\ref{eq:yw})，此公式即可獲的以無人機(相機)與偵測到的車輛之相對位置。
\begin{align}
    x_{w}=\frac{x_{c}}{z_{c}}
    \label{eq:xw}\\
    y_{w}=\frac{y_{c}}{z_{c}}
    \label{eq:yw}
\end{align}

在最後的整合階段，無人機的 GPS 位置作為已知參考點，結合車輛與無人機之間的相對位置，透過 Pyproj 函式庫\cite{pyproj}將這些相對位置轉換為標準的 GPS 坐標。
Pyproj 是基於 PROJ 庫的強大 Python 座標轉換與地理投影工具，專為地理資訊系統(GIS)設計。它提供靈活且精確的座標系統轉換功能，能夠在全球與區域性坐標系統之間進行準確變換，廣泛應用於地圖服務、導航、遙測影像分析等領域。
%==============================內文==============================

\subsection{空間對位}
%==============================內文==============================
\hspace{2em}透過獲取無人機的絕對位置以及相關的飛行參數，可以應用透視變換技術，將無人機拍攝的影像中的像素座標轉換為相對應的GPS座標。
這一過程不僅能夠將影像中的物體位置準確地映射到真實的地理座標系統中，還可以達成對影像位置的精確校正，實現空間對位。
在此基礎上，空間對位的技術將被應用於QGIS(Quantum GIS)\cite{QGIS_software}，這是一款開源的桌面地理信息系統應用程序，廣泛應用於地理數據的分析與處理。

QGIS支持各種地理信息數據格式，並提供豐富的工具與功能，幫助用戶進行數據的導入、匯出及分析。在這項研究中，我將使用QGIS進行空間對位，驗證無人機所拍攝影像中車輛位置的準確性，並與實際地面的位置進行比對。
透過無人機的拍攝影像，可以提取影像中的車輛位置，並將其與已知的GPS座標進行對比。
\begin{figure}[H]
    \centering
    \includegraphics[width=0.7\textwidth]{qgis.jpg}     %圖片檔案名稱
    \caption{QGIS操作畫面\cite{qgis_2020}}    %圖片檔案名稱
    \label{fig:qgis}    %為圖片添加標籤
    %如\ref{fig:qgis}所示
\end{figure}
利用透視變換，將影像中的像素座標轉換成地理座標，並使用QGIS來執行這些座標的空間對位，將影像中的車輛位置對應到地面實際的位置。
接著，將這些透視變換計算得出的GPS座標與現場實際測量得到的GPS座標進行比對，以檢視兩者之間的誤差，從而評估該方法在實際應用中的精度與可靠性。
此方法不僅能夠驗證無人機拍攝影像的地理位置準確性，還能夠提供精確的車輛位置追蹤。
%==============================內文==============================


\section{\centering 研究結果}
%==============================內文==============================
\hspace{2em}研究結果主要分成幾部分，包含飛行路徑規劃、IMU資料獲取

%==============================內文==============================

\subsection{飛行路徑規劃}
%==============================內文==============================
\hspace{2em}在本研究中，無人機的飛行路徑規劃是利用 Mission Planner 軟體來進行的。
Mission Planner 是一款開源的地面控制站軟體，廣泛應用於無人機的航線規劃與監控。
為了確保無人機能夠有效覆蓋所有需要檢測的區域，我們首先根據目標區域的地理範圍及飛行高度設計了航線。

使用 Mission Planner 的自動飛行功能，我們在系統中設定了多個航點，並依據特定的飛行高度和速度來確保無人機在巡檢過程中能夠拍攝到足夠的影像資料。
此外，Mission Planner 也提供了飛行模式的設置，例如「自動」模式，用以精確控制無人機沿預定路徑飛行，並保持穩定的飛行姿態。實際操作如圖\ref{fig:missionplanner2}所示。

\begin{figure}[H]
    \centering
    \includegraphics[width=0.7\textwidth]{missionplanner2.jpg}     %圖片檔案名稱
    \caption{使用MissionPlanner規劃飛行路徑}    %圖片檔案名稱
    \label{fig:missionplanner2}    %為圖片添加標籤
    %如\ref{fig:missionplanner2}所示
\end{figure}

在實際測試中，飛行路徑的規劃與模擬結果均顯示，無人機能夠準確地按照設定的路徑完成巡檢任務。
航線規劃的過程中，考慮到了可能的障礙物和飛行安全距離，並根據實際情況進行了適當的調整。
測試結果證明，Mission Planner 的飛行路徑規劃功能具有良好的可靠性和高效性，成功幫助無人機完成了覆蓋所有檢測區域的任務。
%==============================內文==============================

\subsection{無人機資料獲取}
%==============================內文==============================
\hspace{2em}
在本研究中，無人機的資料獲取主要涉及無人機的姿態、飛行高度和 GPS 位置。
這些資料是透過 MAVLink 協議進行傳輸和獲取的，MAVLink 是一種廣泛應用於無人機通信的開放式協議，支持與多種飛行控制系統進行無縫對接。

無人機的姿態資訊，包括滾轉角(Roll)、俯仰角(Pitch)和航向角(Yaw)，能夠提供無人機的空間定位，這對於影像處理和空間對位至關重要。
高度資料則顯示無人機距地面的實際高度，這對於設計飛行路徑和確保飛行安全十分關鍵，且高度獲取的精確度，會直接影響到地面座標尺度的精確度。
GPS 位置資料則提供了無人機的實時位置，這些位置資料在結合影像處理後，可以精確地定位偵測到的違規車輛。

\begin{figure}[H]
    \centering
    \includegraphics[width=0.7\textwidth]{mavlink.jpg}     %圖片檔案名稱
    \caption{無人機實際資料透過mavlink獲取}    %圖片檔案名稱
    \label{fig:mavlink}    %為圖片添加標籤
    %(如圖\ref{fig:mavlink}所示)
\end{figure}

透過 MAVLink 協議，這些資料能夠實時回傳並被整合到無人機的控制系統中，使得系統能夠即時調整飛行參數並進行後續處理。在測試中，無人機資料的獲取過程非常穩定，資料回傳精確，對於後續影像處理和空間對位提供了強有力的支持。
%==============================內文==============================

\subsection{車輛偵測}
%==============================內文==============================
\hspace{2em}
在車輛偵測方面，本研究使用 YOLOv7 物件偵測模型進行即時車輛識別。
YOLOv7 是一種高效且精確的物件偵測算法，能夠在實時情況下快速識別圖像中的車輛，並且具備出色的精度和速度，適用於大範圍的監控與檢測任務。

為了進一步提高系統的精度與穩定性，我們結合了物件追蹤技術。
在每次車輛偵測後，系統會給每輛車輛分配一個唯一的編號，並持續追蹤其位置，確保在無人機飛行過程中，車輛的動態變化能夠被精確捕捉。
這樣的追蹤功能不僅提高了車輛識別的準確性，還能幫助系統在多車輛環境中區分每輛車輛的位置，從而進行違規停車的判斷。
下圖(如圖\ref{fig:yoloreal}所示)為利用台南市交通局監視器\cite{taiwantrafficvideo}之影像進行測試。

\begin{figure}[H]
    \centering
    \includegraphics[width=0.7\textwidth]{yoloreal2.png}     %圖片檔案名稱
    \caption{Yolov7車輛偵測與追蹤}    %圖片檔案名稱
    \label{fig:yoloreal}    %為圖片添加標籤
    %(如圖\ref{fig:yoloreal}所示)
\end{figure}

在測試過程中，YOLOv7 在各種環境下的表現均十分出色，無論是在白天、夜間或不同的光照條件下，車輛偵測的準確率和速度均達到了預期效果。物件追蹤技術的加入，則進一步提升了車輛識別的穩定性和持續性，確保了系統在巡檢過程中的高效性與可靠性。

下圖(如圖\ref{fig:yoloreal1}所示)為無人機拍攝影像實際偵測之結果。考慮到回傳的 4G 網路可能較不穩定，影像質量有時會受到影響，可能會呈現不清晰或模糊的情形。然而，儘管如此，透過YOLOv7物件偵測模型結合物件追蹤技術，系統仍能有效識別並偵測到車輛。
即使在影像質量不佳的情況下，YOLOv7 的高效能和強大的物件追蹤能力使得車輛的識別與追蹤仍能保持較高的準確度。
為每輛車輛都被分配了一個唯一的編號，並且持續追蹤其動態位置，這有助於在不穩定的網路環境中提高偵測的穩定性與精度。

\begin{figure}[H]
    \centering
    \includegraphics[width=0.7\textwidth]{yoloreal1.jpg}     %圖片檔案名稱
    \caption{Yolov7車輛偵測與追蹤-無人機實拍}    %圖片檔案名稱
    \label{fig:yoloreal1}    %為圖片添加標籤
    %(如圖\ref{fig:yoloreal1}所示)
\end{figure}

測試結果顯示，該系統能夠在多變的條件下，依然保持較好的偵測效能，確保無人機巡檢任務的順利完成。
%==============================內文==============================

\subsection{逆透視變換}
%==============================內文==============================
\hspace{2em}在本研究中，影像處理技術是確保無人機拍攝的影像能準確地轉換為地面真實座標的關鍵。
為了處理斜下角度拍攝所產生的透視變形，使用了逆透視變換 (Inverse Perspective Mapping, IPM) 技術。
這項技術能夠將無人機拍攝的影像中的像素座標轉換為地面座標，克服了因為無人機姿態變化（如翻滾、俯仰、偏航等）而產生的影像扭曲問題。

在具體應用中，首先我們根據無人機的 GPS 位置、飛行高度以及相機的內部參數（例如焦距、視場角等），將每個像素與實際地面位置進行對應。
這一過程的核心在於運用逆透視變換公式來校正影像中的透視扭曲，將相機座標轉換為無人機所在坐標系下的相對位置，最終精確地映射到地面上的絕對位置。

首先先在實驗室內測試，遠圖片如圖\ref{fig:11}所示。
\begin{figure}[H]
    \centering
    \includegraphics[width=0.7\textwidth]{11.jpg}     %圖片檔案名稱
    \caption{尚未進行透視變換之原始圖片}    %圖片檔案名稱
    \label{fig:11}    %為圖片添加標籤
    %如\ref{fig:11}所示
\end{figure}
經透視變換後的圖片如圖\ref{fig:33}所示，該圖以透過根據無人機的 GPS 位置、飛行高度以及相機的內部參數（例如焦距、視場角等），將圖像投影至以無人機維園點的座標中。
\begin{figure}[H]
    \centering
    \includegraphics[width=0.7\textwidth]{33.jpg}     %圖片檔案名稱
    \caption{進行透視變換後圖片}    %圖片檔案名稱
    \label{fig:33}    %為圖片添加標籤
    %如\ref{fig:11}所示
\end{figure}

加上無人機之座標如圖\ref{fig:22}所示。依照圖\ref{fig:22}，即可得知目標物與無人機在同一平面之距離。

\begin{figure}[H]
    \centering
    \includegraphics[width=0.7\textwidth]{22.jpg}     %圖片檔案名稱
    \caption{經透視變換後影像之無人機座標}    %圖片檔案名稱
    \label{fig:22}    %為圖片添加標籤
    %如\ref{fig:MxzONoG}所示
\end{figure}

而經過轉換，即可得知該目標物之GPS座標(如圖\ref{fig:44}所示)。
\begin{figure}[H]
    \centering
    \includegraphics[width=0.7\textwidth]{44.jpg}     %圖片檔案名稱
    \caption{經透視變換後影像之GPS座標}    %圖片檔案名稱
    \label{fig:44}    %為圖片添加標籤
    %如\ref{fig:MxzONoG}所示
\end{figure}

在利用透視變換取的目標物之座標後，使用逆透視變換，將拍攝影像回推各像素間實際之距離，可推算測量之精確度。已知一個地磚是60公分，下圖(如圖\ref{fig:frame_with_points_real}所示)為實際測量之結果。

\begin{figure}[H]
    \centering
    \includegraphics[width=0.7\textwidth]{frame_with_points_real.jpg}     %圖片檔案名稱
    \caption{實際測量地板尺寸}    %圖片檔案名稱
    \label{fig:frame_with_points_real}    %為圖片添加標籤
    %(如圖\ref{fig:frame_with_points_real}所示)
\end{figure}

誤差如下表(如表\ref{tab:error_comparison}所示)所示，依照當時獲取之無人機資訊，平均絕對誤差(MAE)為0.7公分，平均相對誤差(MRE)約為1$\%$左右。

\begin{table}[H]
    \centering
    \caption{透視變換誤差}
    \vspace{6pt} % 增加空格
    \label{tab:error_comparison}
    \begin{tabular}{lS[table-format=2.2]S[table-format=2.2]}
        \toprule
        MAE(m) & 0.007  \\
        MRE(\%) & 1.168 \\
        \bottomrule
    \end{tabular}
\end{table}

由實際測量可知，若無人機的資料傳輸無延遲，參數傳輸理想，可活相當高精度之車輛位置。
%==============================內文==============================

\subsection{空間對位}
%==============================內文==============================
\hspace{2em}在本研究中，為了將無人機拍攝的影像中偵測到的車輛位置精確對應到地面實際地理坐標，我們採用了QGIS (Quantum GIS)和Google 地圖進行空間對位。這一過程主要通過將無人機拍攝的影像與已知的地理參考資料進行匹配，實現車輛位置的精確定位，比較計算值和實際值。

具體來說，我們首先將無人機拍攝的影像與從無人機獲得的 GPS 位置資料結合，並將其轉換為可用於地理參考的格式。接著，我們在 QGIS 中使用影像配準工具，將影像中的車輛位置與 Google 地圖上的對應位置進行匹配，將無人機拍攝的影像與真實的地理坐標系統對應起來。這樣的對位過程使得影像中的車輛位置可以轉換為地面上的實際 GPS 位置，從而達到精確定位的目的。
因尚未取得無人機空拍影像，下圖為利用QGIS將兩張地圖進行空間對位之測試。
\begin{figure}[H]
    \centering
    \includegraphics[width=0.7\textwidth]{1234567890.png}     %圖片檔案名稱
    \caption{空間對位測試}    %圖片檔案名稱
    \label{fig:1234567890}    %為圖片添加標籤
    %(如圖\ref{fig:1234567890}所示)
\end{figure}
%==============================內文==============================

\section{\centering 結論} 
%==============================內文==============================
\hspace{2em}本研究成功開發了一套利用無人機進行違規停車車輛偵測的智慧交通巡檢系統，並採用先進的技術來提高偵測準確性與效率。
系統的核心架構基於 YOLOv7 物件偵測模型和 MAVLink 資料傳輸協議，結合了無人機的 GPS 定位資訊與飛行姿態，通過逆透視變換技術將影像中的車輛位置映射到真實地理座標系統中，從而實現高精度的違規車輛檢測。

飛行路徑的規劃通過 Mission Planner 軟體進行，確保無人機能夠有效覆蓋所有檢測區域。
經過測試，該系統在多變的環境條件下仍能保持穩定運行，有效識別並追蹤車輛位置，即使在網路不穩定或影像質量不佳的情況下，也能保持較高的偵測精度。

影像處理方面，逆透視變換技術成功地將斜拍的影像轉換為地面座標，並且經過空間對位處理後，偵測到的車輛位置與實際 GPS 位置之間的誤差十分微小，顯示出該系統在精確定位方面的優越性。
測試結果顯示，系統在偵測與定位的準確性上達到了預期，且 MAE（平均絕對誤差）僅為 0.007 米，MRE（平均相對誤差）為 1.168$\%$。

總結來看，本研究所設計的無人機違規停車偵測系統，不僅具備高效、準確的車輛識別與追蹤能力，還能在不同的測量環境中提供穩定可靠的結果。
該系統具有良好的應用前景，可進一步提升交通執法的靈活性與效率，並有潛力在智慧城市建設中發揮重要作用。
%==============================內文==============================

\section{\centering 參考文獻}
\vspace{-3.5em}  % 減少與上方內容的間距
\renewcommand{\refname}{}  % 去除 "References" 標題
\printbibliography  % 列出參考文獻

\end{document}

%=============================================================================================================================
%=============================================================================================================================
%=============================================================================================================================


\begin{comment}
    %==============================圖片==============================
\begin{figure}[H]
    \centering
    \includegraphics[width=0.7\textwidth]{截圖 2025-01-24 03.21.17.jpg}     %圖片檔案名稱
    \caption{這是圖片的標題}    %圖片檔案名稱
    \label{fig:example2}    %為圖片添加標籤
    %如\ref{fig:example1}所示
\end{figure}
    
    %==============================數學公式==============================
\begin{align}
    a &= b + c \label{eq:1}
    \\
    d &= e - f \label{eq:2}
    %式label{eq:2}
\end{align}
    
    %==============================表格==============================
\begin{table}[H]
    \caption{MSI GP76 Leopard規格}
    \vspace{12pt} % 增加空格
    \renewcommand{\arraystretch}{1.5} % 調整行距以垂直置中
    \centering
    \begin{tabular}{|c|c|}
        \hline
        \textbf{元件} & \textbf{規格}                 \\ \hline
        中央處理器       & Intel(R) Core(TM) i7-10870H \\ \hline
        記憶體         & DDR4 16GB                   \\ \hline
        硬碟          & 1TB SSD                     \\ \hline
        顯卡          & NVIDIA® GeForce® RTX 3060   \\ \hline
        作業系統        & Ubuntu 18.04                \\ \hline
        電池          & 4-Cell 65 Battery (Whr)     \\ \hline
    \end{tabular}
    \label{tab:MSI GP76 Leopard}
    %(具體規格詳見表\ref{tab:MSI GP76 Leopard})
\end{table}
    
\begin{table}[H]
    \centering
    \caption{C922 Pro Stream 規格}
    \vspace{6pt} % 增加空格
    \label{tab:C922 Pro}
    \begin{tabular}{ll}
        \toprule
        \textbf{項目} & \textbf{規格} \\
        \midrule
        解析度  & 1280$\times$720 (HD) \\
        幀率  & 30fps \\
        水平視角 & 70.42$^\circ$ \\
        垂直視角  & 43.3$^\circ$ \\
        \bottomrule
    \end{tabular}
\end{table}

    \end{comment}
        